{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade snowflake-connector-python\n",
    "# pip install --upgrade snowflake-sqlalchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import snowflake.connector\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user='wbkennedy',\n",
    "    password='Brandon92!',\n",
    "    account='nulgoll-hsb06466',\n",
    "    warehouse='final_project_warehouse',\n",
    "    database='final_project_db',\n",
    "    schema='final_project_schema'\n",
    ")\n",
    "\n",
    "cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f9336fbdd10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a virtual warehouse (virtual warehouses contain the compute resources that are required to perform queries and DML operations with Snowflake)\n",
    "cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS final_project_warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f93376a0e90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a database\n",
    "cs.execute(\"CREATE DATABASE IF NOT EXISTS final_project_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f93376a0e90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create schema\n",
    "cs.execute(\"CREATE SCHEMA IF NOT EXISTS final_project_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f93376a0e90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Snowflake stage to hold the files\n",
    "stage_name = \"purchases_stage\"\n",
    "cs.execute(f\"CREATE OR REPLACE STAGE {stage_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the CSV files (your provided path)\n",
    "csv_folder_path = '/home/jovyan/MGTA_464/data/Data_unzipped/Data/Monthly_PO_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2020-2.csv to Snowflake stage\n",
      "Uploaded 2021-3.csv to Snowflake stage\n",
      "Uploaded 2020-5.csv to Snowflake stage\n",
      "Uploaded 2021-11.csv to Snowflake stage\n",
      "Uploaded 2022-1.csv to Snowflake stage\n",
      "Uploaded 2019-8.csv to Snowflake stage\n",
      "Uploaded 2021-7.csv to Snowflake stage\n",
      "Uploaded 2021-10.csv to Snowflake stage\n",
      "Uploaded 2019-6.csv to Snowflake stage\n",
      "Uploaded 2021-8.csv to Snowflake stage\n",
      "Uploaded 2020-10.csv to Snowflake stage\n",
      "Uploaded 2020-8.csv to Snowflake stage\n",
      "Uploaded 2021-1.csv to Snowflake stage\n",
      "Uploaded 2019-4.csv to Snowflake stage\n",
      "Uploaded 2019-12.csv to Snowflake stage\n",
      "Uploaded 2022-4.csv to Snowflake stage\n",
      "Uploaded 2020-11.csv to Snowflake stage\n",
      "Uploaded 2019-10.csv to Snowflake stage\n",
      "Uploaded 2020-12.csv to Snowflake stage\n",
      "Uploaded 2020-3.csv to Snowflake stage\n",
      "Uploaded 2020-1.csv to Snowflake stage\n",
      "Uploaded 2019-2.csv to Snowflake stage\n",
      "Uploaded 2019-11.csv to Snowflake stage\n",
      "Uploaded 2021-2.csv to Snowflake stage\n",
      "Uploaded 2019-3.csv to Snowflake stage\n",
      "Uploaded 2019-9.csv to Snowflake stage\n",
      "Uploaded 2021-12.csv to Snowflake stage\n",
      "Uploaded 2021-5.csv to Snowflake stage\n",
      "Uploaded 2020-4.csv to Snowflake stage\n",
      "Uploaded 2022-5.csv to Snowflake stage\n",
      "Uploaded 2020-6.csv to Snowflake stage\n",
      "Uploaded 2019-7.csv to Snowflake stage\n",
      "Uploaded 2021-9.csv to Snowflake stage\n",
      "Uploaded 2022-2.csv to Snowflake stage\n",
      "Uploaded 2019-1.csv to Snowflake stage\n",
      "Uploaded 2020-7.csv to Snowflake stage\n",
      "Uploaded 2019-5.csv to Snowflake stage\n",
      "Uploaded 2022-3.csv to Snowflake stage\n",
      "Uploaded 2021-4.csv to Snowflake stage\n",
      "Uploaded 2021-6.csv to Snowflake stage\n",
      "Uploaded 2020-9.csv to Snowflake stage\n",
      "Created table purchases_data\n",
      "Data copied from stage to purchases_data table\n",
      "Removed files from stage purchases_stage\n"
     ]
    }
   ],
   "source": [
    "# Use glob to iterate through all CSV files in the directory and upload them to the stage\n",
    "for file_path in glob.glob(os.path.join(csv_folder_path, \"*.csv\")):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Upload the file to the Snowflake stage\n",
    "    put_query = f\"PUT file://{file_path} @{stage_name}/{file_name}\"\n",
    "    cs.execute(put_query)\n",
    "    print(f\"Uploaded {file_name} to Snowflake stage\")\n",
    "\n",
    "# Create a target table in Snowflake with proper data types\n",
    "cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE purchases_data (\n",
    "        PurchaseOrderID INTEGER,\n",
    "        SupplierID INTEGER,\n",
    "        OrderDate DATE,\n",
    "        DeliveryMethodID INTEGER,\n",
    "        ContactPersonID INTEGER,\n",
    "        ExpectedDeliveryDate DATE,\n",
    "        SupplierReference STRING,\n",
    "        IsOrderFinalized BOOLEAN,\n",
    "        Comments STRING,\n",
    "        InternalComments STRING,\n",
    "        LastEditedBy INTEGER,\n",
    "        LastEditedWhen TIMESTAMP,\n",
    "        PurchaseOrderLineID INTEGER,\n",
    "        StockItemID INTEGER,\n",
    "        OrderedOuters INTEGER,\n",
    "        Description STRING,\n",
    "        ReceivedOuters INTEGER,\n",
    "        PackageTypeID INTEGER,\n",
    "        ExpectedUnitPricePerOuter FLOAT,\n",
    "        LastReceiptDate DATE,\n",
    "        IsOrderLineFinalized BOOLEAN,\n",
    "        Right_LastEditedBy INTEGER,\n",
    "        Right_LastEditedWhen TIMESTAMP\n",
    "    );\n",
    "\"\"\")\n",
    "print(\"Created table purchases_data\")\n",
    "\n",
    "# Use COPY INTO to move data from the stage to the Snowflake table, with correct formatting and error handling\n",
    "copy_into_query = f\"\"\"\n",
    "COPY INTO purchases_data\n",
    "FROM @{stage_name}\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'CSV',\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"',\n",
    "    SKIP_HEADER = 1,\n",
    "    DATE_FORMAT = 'MM/DD/YYYY',\n",
    "    TIMESTAMP_FORMAT = 'MM/DD/YYYY HH24:MI'\n",
    ")\n",
    "ON_ERROR = 'CONTINUE';\n",
    "\"\"\"\n",
    "cs.execute(copy_into_query)\n",
    "print(\"Data copied from stage to purchases_data table\")\n",
    "\n",
    "# Optionally, you can remove the files from the stage after loading them to the table\n",
    "cs.execute(f\"REMOVE @{stage_name}\")\n",
    "print(f\"Removed files from stage {stage_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object\n",
    "cs = conn.cursor()\n",
    "\n",
    "# Add the POAmount column\n",
    "cs.execute(\"\"\"\n",
    "    ALTER TABLE purchases_data\n",
    "    ADD COLUMN POAmount FLOAT;\n",
    "\"\"\")\n",
    "print(\"Added POAmount column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated POAmount values\n"
     ]
    }
   ],
   "source": [
    "# Update the table to calculate POAmount\n",
    "cs.execute(\"\"\"\n",
    "    UPDATE purchases_data\n",
    "    SET POAmount = ReceivedOuters * ExpectedUnitPricePerOuter;\n",
    "\"\"\")\n",
    "print(\"Updated POAmount values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage created\n",
      "File uploaded to Snowflake stage\n",
      "Raw table created\n",
      "XML data loaded into raw table\n",
      "Final table created\n",
      "Data shredded and inserted into the final table\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create a Stage for XML File\n",
    "cs.execute(\"CREATE OR REPLACE STAGE supplier_stage\")\n",
    "print(\"Stage created\")\n",
    "\n",
    "# Step 3: Upload XML File into the Stage\n",
    "cs.execute(\"PUT file:///home/jovyan/MGTA_464/data/Data_unzipped/Data/SupplierTransactionsXML.xml @supplier_stage\")\n",
    "print(\"File uploaded to Snowflake stage\")\n",
    "\n",
    "# Step 4: Create Raw Table to Hold XML Data\n",
    "cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE supplier_transactions_raw (xml_data VARIANT)\n",
    "\"\"\")\n",
    "print(\"Raw table created\")\n",
    "\n",
    "# Step 5: Copy XML into Raw Table\n",
    "cs.execute(\"\"\"\n",
    "    COPY INTO supplier_transactions_raw\n",
    "    FROM @supplier_stage FILE_FORMAT = (TYPE = 'XML')\n",
    "\"\"\")\n",
    "print(\"XML data loaded into raw table\")\n",
    "\n",
    "# Step 6: Create the Final Table for Shredded Data\n",
    "cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE supplier_transactions (\n",
    "        SupplierTransactionID STRING, SupplierID STRING, TransactionTypeID STRING,\n",
    "        PurchaseOrderID STRING, PaymentMethodID STRING, SupplierInvoiceNumber STRING,\n",
    "        TransactionDate DATE, AmountExcludingTax FLOAT, TaxAmount FLOAT,\n",
    "        TransactionAmount FLOAT, OutstandingBalance FLOAT, FinalizationDate DATE,\n",
    "        IsFinalized BOOLEAN, LastEditedBy STRING, LastEditedWhen TIMESTAMP\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"Final table created\")\n",
    "\n",
    "# Step 7: Shred XML Data Using LATERAL FLATTEN in Snowflake\n",
    "cs.execute(\"\"\"\n",
    "    INSERT INTO supplier_transactions\n",
    "    SELECT \n",
    "        value:SupplierTransactionID::STRING AS SupplierTransactionID,\n",
    "        value:SupplierID::STRING AS SupplierID,\n",
    "        value:TransactionTypeID::STRING AS TransactionTypeID,\n",
    "        value:PurchaseOrderID::STRING AS PurchaseOrderID,\n",
    "        value:PaymentMethodID::STRING AS PaymentMethodID,\n",
    "        value:SupplierInvoiceNumber::STRING AS SupplierInvoiceNumber,\n",
    "        TO_DATE(value:TransactionDate::STRING, 'YYYY-MM-DD') AS TransactionDate,\n",
    "        value:AmountExcludingTax::FLOAT AS AmountExcludingTax,\n",
    "        value:TaxAmount::FLOAT AS TaxAmount,\n",
    "        value:TransactionAmount::FLOAT AS TransactionAmount,\n",
    "        value:OutstandingBalance::FLOAT AS OutstandingBalance,\n",
    "        TO_DATE(value:FinalizationDate::STRING, 'YYYY-MM-DD') AS FinalizationDate,\n",
    "        value:IsFinalized::BOOLEAN AS IsFinalized,\n",
    "        value:LastEditedBy::STRING AS LastEditedBy,\n",
    "        TO_TIMESTAMP(value:LastEditedWhen::STRING) AS LastEditedWhen\n",
    "    FROM supplier_transactions_raw,\n",
    "    LATERAL FLATTEN(input => supplier_transactions_raw.xml_data:\"root\".\"row\")\n",
    "\"\"\")\n",
    "print(\"Data shredded and inserted into the final table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.execute(\"\"\"\n",
    "    SELECT \n",
    "        value:SupplierTransactionID::STRING AS SupplierTransactionID,\n",
    "        value:SupplierID::STRING AS SupplierID,\n",
    "        value:TransactionTypeID::STRING AS TransactionTypeID\n",
    "    FROM supplier_transactions_raw,\n",
    "    LATERAL FLATTEN(input => supplier_transactions_raw.xml_data:\"root\".\"row\")\n",
    "    LIMIT 10;\n",
    "\"\"\")\n",
    "rows = cs.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # query the table\n",
    "# cs.execute('SELECT * FROM purchases_data LIMIT 10')\n",
    "# print(cs.fetchmany(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs.execute('SELECT * FROM purchases_data LIMIT 100')\n",
    "# result = cs.fetchall()\n",
    "# for row in result:\n",
    "#     print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to use a different warehouse\n",
    "# cs.execute(\"USE WAREHOUSE different_warehouse_mg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f11b7eca410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # create table and insert data\n",
    "# cs.execute(\"CREATE OR REPLACE TABLE test_table(col1 integer, col2 string)\")\n",
    "# cs.execute(\"INSERT INTO test_table(col1, col2) VALUES (123, 'test string1'), (456, 'test string2')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('/home/jovyan/MGTA_464/data/Data_unzipped/Data/SupplierTransactionsXML.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Create CSV file\n",
    "with open('SupplierTransactions.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\n",
    "        'SupplierTransactionID', 'SupplierID', 'TransactionTypeID', 'PurchaseOrderID', \n",
    "        'PaymentMethodID', 'SupplierInvoiceNumber', 'TransactionDate', \n",
    "        'AmountExcludingTax', 'TaxAmount', 'TransactionAmount', \n",
    "        'OutstandingBalance', 'FinalizationDate', 'IsFinalized', \n",
    "        'LastEditedBy', 'LastEditedWhen'\n",
    "    ])\n",
    "\n",
    "    for row in root.findall('row'):\n",
    "        writer.writerow([\n",
    "            row.find('SupplierTransactionID').text,\n",
    "            row.find('SupplierID').text,\n",
    "            row.find('TransactionTypeID').text,\n",
    "            row.find('PurchaseOrderID').text,\n",
    "            row.find('PaymentMethodID').text,\n",
    "            row.find('SupplierInvoiceNumber').text,\n",
    "            row.find('TransactionDate').text,\n",
    "            row.find('AmountExcludingTax').text,\n",
    "            row.find('TaxAmount').text,\n",
    "            row.find('TransactionAmount').text,\n",
    "            row.find('OutstandingBalance').text,\n",
    "            row.find('FinalizationDate').text,\n",
    "            row.find('IsFinalized').text,\n",
    "            row.find('LastEditedBy').text,\n",
    "            row.find('LastEditedWhen').text\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from CSV file\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"PUT file://SupplierTransactions.csv @supplier_stage\")  # For CSV\n",
    "cs.execute(\"\"\"\n",
    "    COPY INTO supplier_transactions\n",
    "    FROM @supplier_stage/SupplierTransactions.csv\n",
    "    FILE_FORMAT = (TYPE = 'CSV', SKIP_HEADER = 1);\n",
    "\"\"\")\n",
    "print(\"Data loaded from CSV file\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('134', '2', '5', '1', '4', '7290', datetime.date(2019, 1, 2), 313.5, 47.03, 360.53, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('169', '4', '5', '2', '4', '3898', datetime.date(2019, 1, 2), 21732.0, 3259.8, 24991.8, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('186', '5', '5', '3', '4', '616', datetime.date(2019, 1, 2), 2740.5, 411.11, 3151.61, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('215', '7', '5', '4', '4', '3869', datetime.date(2019, 1, 2), 42481.2, 6372.19, 48853.39, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('224', '10', '5', '5', '4', '4697', datetime.date(2019, 1, 2), 35067.5, 5260.14, 40327.64, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('230', '12', '5', '6', '4', '1375', datetime.date(2019, 1, 2), 5528.5, 829.28, 6357.78, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('565', '4', '5', '7', '4', '3261', datetime.date(2019, 1, 3), 10000.5, 1500.08, 11500.58, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('570', '5', '5', '8', '4', '1762', datetime.date(2019, 1, 3), 657.0, 98.56, 755.56, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('588', '7', '5', '9', '4', '9301', datetime.date(2019, 1, 3), 9281.5, 1392.24, 10673.74, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n",
      "('590', '10', '5', '10', '4', '1853', datetime.date(2019, 1, 3), 1037.5, 155.63, 1193.13, 0.0, datetime.date(2019, 1, 7), True, '4', datetime.datetime(2019, 1, 7, 9, 0))\n"
     ]
    }
   ],
   "source": [
    "# Query the data from supplier_transactions\n",
    "cs.execute(\"SELECT * FROM supplier_transactions LIMIT 10\")\n",
    "rows = cs.fetchall()\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to supplier_case.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "def export_postgres_to_csv(db_conn_str, query, output_file):\n",
    "    conn = psycopg2.connect(db_conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        cursor.copy_expert(f\"COPY ({query}) TO STDOUT WITH CSV HEADER\", f)\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"Data exported to {output_file}\")\n",
    "\n",
    "# Connection string to your Postgres database\n",
    "postgres_conn_str = \"dbname='WestCoastImporters' user='jovyan' host='127.0.0.1' port='8765' password='postgres'\"\n",
    "\n",
    "# SQL query to extract the data from the table\n",
    "query = \"SELECT * FROM supplier_case\"\n",
    "\n",
    "# Export data to CSV\n",
    "export_postgres_to_csv(postgres_conn_str, query, \"supplier_case.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded supplier_case.csv to Snowflake stage\n"
     ]
    }
   ],
   "source": [
    "# Upload the CSV file to the Snowflake stage\n",
    "stage_name = \"supplier_stage\"\n",
    "csv_file = \"supplier_case.csv\"\n",
    "\n",
    "cs.execute(f\"PUT file://{csv_file} @{stage_name}\")\n",
    "print(f\"Uploaded {csv_file} to Snowflake stage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created supplier_case table in Snowflake\n"
     ]
    }
   ],
   "source": [
    "# Create the table before loading data\n",
    "cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE supplier_case (\n",
    "        supplierid STRING,\n",
    "        suppliername STRING,\n",
    "        suppliercategoryid STRING,\n",
    "        primarycontactpersonid STRING,\n",
    "        alternatecontactpersonid STRING,\n",
    "        deliverymethodid STRING,\n",
    "        postalcityid STRING,\n",
    "        supplierreference STRING,\n",
    "        bankaccountname STRING,\n",
    "        bankaccountbranch STRING,\n",
    "        bankaccountcode STRING,\n",
    "        bankaccountnumber STRING,\n",
    "        bankinternationalcode STRING,\n",
    "        paymentdays INT,\n",
    "        internalcomments STRING,\n",
    "        phonenumber STRING,\n",
    "        faxnumber STRING,\n",
    "        websiteurl STRING,\n",
    "        deliveryaddressline1 STRING,\n",
    "        deliveryaddressline2 STRING,\n",
    "        deliverypostalcode STRING,\n",
    "        deliverylocation STRING,\n",
    "        postaladdressline1 STRING,\n",
    "        postaladdressline2 STRING,\n",
    "        postalpostalcode STRING,\n",
    "        lasteditedby STRING,\n",
    "        validfrom STRING,\n",
    "        validto STRING\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"Created supplier_case table in Snowflake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into the supplier_case table\n"
     ]
    }
   ],
   "source": [
    "# Define a file format with proper handling for enclosed fields\n",
    "cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE FILE FORMAT my_csv_format\n",
    "    TYPE = 'CSV'\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "    SKIP_HEADER = 1\n",
    "    NULL_IF = ('');\n",
    "\"\"\")\n",
    "\n",
    "# Copy data from the Snowflake stage to the table using the custom file format\n",
    "cs.execute(f\"\"\"\n",
    "    COPY INTO supplier_case\n",
    "    FROM @{stage_name}/{csv_file.split('/')[-1]}\n",
    "    FILE_FORMAT = my_csv_format;\n",
    "\"\"\")\n",
    "print(\"Data loaded into the supplier_case table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE purchase_orders_and_invoices AS\n",
    "    SELECT \n",
    "    \n",
    "        (ST.AmountExcludingTax - PD.POAmount) AS invoiced_vs_quoted,\n",
    "    FROM PURCHASES_DATA PD\n",
    "    INNER JOIN SUPPLIER_TRANSACTIONS ST\n",
    "    ON PD.PurchaseOrderID = ST.PurchaseOrderID\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"Table 'purchase_orders_and_invoices' created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
